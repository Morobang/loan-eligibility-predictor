# Loan Eligibility Predictor

![Python](https://img.shields.io/badge/Python-3.8%2B-blue)
![Scikit-learn](https://img.shields.io/badge/Scikit--learn-1.0%2B-orange)
![License](https://img.shields.io/badge/License-MIT-green)
![Status](https://img.shields.io/badge/Status-Active-success)

A machine learning pipeline to predict loan eligibility based on applicant data. This project implements a complete ML workflow from exploratory data analysis to model deployment.

## ğŸ“‹ Project Overview

Financial institutions receive numerous loan applications daily. Manual processing is time-consuming and subjective. This project automates the initial screening process using machine learning to predict whether a loan application should be approved based on applicant characteristics.

**Dataset**: [Kaggle Loan Eligibility Dataset](https://www.kaggle.com/datasets/vikasukani/loan-eligible-dataset)  
**Goal**: Build an accurate and interpretable model to predict loan approval status

## ğŸ¯ Key Features

- **Complete ML Pipeline**: End-to-end workflow from raw data to predictions
- **Multiple Models**: Compare Random Forest, XGBoost, Logistic Regression, and more
- **Feature Importance**: Understand what factors drive loan decisions
- **Model Interpretation**: SHAP values and partial dependence plots
- **Production Ready**: Save trained models for deployment

## ğŸ“ Project Structure

```
loan-eligibility-predictor/
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw/                    # Original dataset from Kaggle
â”‚   â”œâ”€â”€ processed/              # Cleaned and processed data
â”‚   â””â”€â”€ external/               # Additional data sources
â”œâ”€â”€ notebooks/
â”‚   â”œâ”€â”€ 01_eda.ipynb           # Exploratory Data Analysis
â”‚   â”œâ”€â”€ 02_preprocessing.ipynb # Data cleaning & feature engineering
â”‚   â”œâ”€â”€ 03_modeling.ipynb      # Model training & evaluation
â”‚   â””â”€â”€ 04_interpretation.ipynb# Model interpretation & insights
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ data_preprocessing.py  # Data cleaning functions
â”‚   â”œâ”€â”€ feature_engineering.py # Feature creation
â”‚   â”œâ”€â”€ model_training.py      # Model training pipeline
â”‚   â”œâ”€â”€ predict.py             # Prediction functions
â”‚   â””â”€â”€ utils.py               # Utility functions
â”œâ”€â”€ models/                    # Saved models (.pkl files)
â”œâ”€â”€ config/                   # Configuration files
â”œâ”€â”€ tests/                    # Unit tests
â”œâ”€â”€ requirements.txt          # Python dependencies
â”œâ”€â”€ config.yaml              # Project configuration
â””â”€â”€ README.md                # This file
```

## ğŸ“Š Dataset Features

The dataset contains 13 features about loan applicants:

**Applicant Information:**
- `Loan_ID`: Unique Loan ID
- `Gender`: Male/Female
- `Married`: Applicant married (Y/N)
- `Dependents`: Number of dependents
- `Education`: Graduate/Not Graduate
- `Self_Employed`: Self-employed (Y/N)
- `ApplicantIncome`: Applicant income
- `CoapplicantIncome`: Coapplicant income

**Loan Details:**
- `LoanAmount`: Loan amount in thousands
- `Loan_Amount_Term`: Term of loan in months
- `Credit_History`: Credit history meets guidelines (1=Yes, 0=No)
- `Property_Area`: Urban/Semi-Urban/Rural

**Target Variable:**
- `Loan_Status`: Loan approved (Y/N)

## ğŸš€ Quick Start

### 1. Clone the Repository
```bash
git clone https://github.com/yourusername/loan-eligibility-predictor.git
cd loan-eligibility-predictor
```

### 2. Install Dependencies
```bash
pip install -r requirements.txt
```

### 3. Download the Dataset
Place the `loan-train.csv` file from Kaggle in the `data/raw/` directory.

### 4. Run the Pipeline
```bash
# Option 1: Run Jupyter notebooks in order
jupyter notebook notebooks/

# Option 2: Run the complete pipeline from command line
python src/main.py
```

## ğŸ› ï¸ Installation

### Prerequisites
- Python 3.8+
- pip or conda

### Using pip
```bash
pip install -r requirements.txt
```

### Using conda
```bash
conda create -n loan-predictor python=3.8
conda activate loan-predictor
pip install -r requirements.txt
```

## ğŸ“ˆ Usage

### 1. Data Exploration
```python
import pandas as pd
from src.data_preprocessing import load_data

df = load_data('data/raw/loan-train.csv')
print(df.info())
print(df.describe())
```

### 2. Training a Model
```python
from src.model_training import train_model
from src.data_preprocessing import preprocess_data

# Load and preprocess data
X_train, X_test, y_train, y_test = preprocess_data('data/raw/loan-train.csv')

# Train model
model, metrics = train_model(X_train, y_train, X_test, y_test, model_type='random_forest')
print(f"Accuracy: {metrics['accuracy']:.2f}")
```

### 3. Making Predictions
```python
from src.predict import predict_loan_eligibility

# Load trained model
model_path = 'models/best_model.pkl'

# New applicant data
new_applicant = {
    'Gender': 'Male',
    'Married': 'Yes',
    'Dependents': '0',
    'Education': 'Graduate',
    'Self_Employed': 'No',
    'ApplicantIncome': 5000,
    'CoapplicantIncome': 2000,
    'LoanAmount': 150,
    'Loan_Amount_Term': 360,
    'Credit_History': 1,
    'Property_Area': 'Urban'
}

# Make prediction
prediction, probability = predict_loan_eligibility(model_path, new_applicant)
print(f"Loan Approved: {prediction}, Probability: {probability:.2f}")
```

## ğŸ¤– Models Implemented

| Model | Accuracy | Precision | Recall | F1-Score |
|-------|----------|-----------|--------|----------|
| Random Forest | 0.84 | 0.86 | 0.94 | 0.90 |
| XGBoost | 0.83 | 0.85 | 0.93 | 0.89 |
| Logistic Regression | 0.81 | 0.83 | 0.92 | 0.87 |
| Gradient Boosting | 0.82 | 0.84 | 0.93 | 0.88 |

*Note: Performance may vary based on hyperparameters and data splits*

## ğŸ” Key Findings

1. **Most Important Features**:
   - Credit History (most significant)
   - Applicant Income
   - Loan Amount
   - Coapplicant Income

2. **Data Insights**:
   - Applicants with good credit history are 5x more likely to get loans
   - Higher income applicants have better approval rates
   - Urban applicants have slightly higher approval rates

3. **Model Performance**:
   - Random Forest performed best overall
   - Ensemble methods outperformed linear models
   - Credit history is the dominant predictive feature

## ğŸ“Š Results Visualization

The project includes comprehensive visualizations:
- Feature distributions and correlations
- Model performance comparisons
- ROC curves and confusion matrices
- SHAP values for model interpretation
- Partial dependence plots

![Model Performance](docs/images/model_comparison.png)
*Example model comparison chart*

## ğŸ§ª Testing

Run the test suite:
```bash
pytest tests/ -v
```

## ğŸ“ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

## ğŸ¤ Contributing

Contributions are welcome! Please feel free to submit a Pull Request.

1. Fork the repository
2. Create your feature branch (`git checkout -b feature/AmazingFeature`)
3. Commit your changes (`git commit -m 'Add some AmazingFeature'`)
4. Push to the branch (`git push origin feature/AmazingFeature`)
5. Open a Pull Request

## ğŸ™ Acknowledgments

- Dataset provided by [Kaggle](https://www.kaggle.com/datasets/vikasukani/loan-eligible-dataset)
- Inspired by real-world loan approval systems
- Built with open-source Python libraries

## ğŸ“§ Contact

Your Name - [@yourusername](https://twitter.com/yourusername) - email@example.com

Project Link: [https://github.com/Morobang/loan-eligibility-predictor](https://github.com/Morobang/loan-eligibility-predictor)

---

**â­ If you found this project helpful, please give it a star on GitHub!**

---

